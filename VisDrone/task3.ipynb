{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: single-object tracking challenge. The task aims to estimate the state of a target, indicated in the first frame, in the subsequent video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as io\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from utils.utils_funcitons import *\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'.\\dataset\\Task3_Single_Object_Tracking'\n",
    "sequences_folder = os.path.join(dataset_path, 'sequences')\n",
    "annotations_folder = os.path.join(dataset_path, 'annotations')\n",
    "model_path = r'.\\models\\best_yolov8n.pt'\n",
    "#model_path = r'.\\models\\yolov8s.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 Object Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)\n",
    "\n",
    "# Images folder path\n",
    "#img_folder = os.path.join(sequences_folder, 'uav0000053_00264_s') #people\n",
    "img_folder = os.path.join(sequences_folder, 'uav0000317_00000_s') #motor\n",
    "#img_folder = os.path.join(sequences_folder, 'uav0000115_00606_s') #car\n",
    "img_names = sorted(os.listdir(img_folder))\n",
    "\n",
    "# Video size\n",
    "width, height = 1280, 720\n",
    "\n",
    "# Codec and VideoWriter\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = 30\n",
    "output_video = cv2.VideoWriter(r'.\\outputs\\Task3\\output_yolo.mp4', codec, fps, (width, height))\n",
    "\n",
    "# Frame processing\n",
    "for i, img in enumerate(img_names):\n",
    "    img_fullpath = os.path.join(img_folder, img)\n",
    "    frame = cv2.imread(img_fullpath)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if frame is not None:\n",
    "        # Redimensionar la imagen si es necesario\n",
    "        if width and height:\n",
    "            result_boxes = track_objects(model, frame, objects=['motor'], conf_thresh=0.3, iou=0.5, imgsz=1280, tracker=r'.\\botsort_custom.yaml')\n",
    "            # Detection control. If no detections were found, use the original frame\n",
    "            if len(result_boxes[0].cls) > 0 and result_boxes[0].id != None: \n",
    "                pred_cls = result_boxes[0].cls.detach().cpu().numpy()\n",
    "                conf = result_boxes[0].conf.detach().cpu().numpy()\n",
    "                bboxes_xyxy = result_boxes[0].xyxy.detach().cpu().numpy()\n",
    "                track_id = result_boxes[0].id\n",
    "                \n",
    "                #ID to track in order to match with annotations folder files\n",
    "                obj_id_to_track = 2\n",
    "                pos = torch.nonzero(track_id == obj_id_to_track)[0,0] if torch.nonzero(track_id == obj_id_to_track).nelement() != 0 else None\n",
    "\n",
    "                if pos != None:\n",
    "                    cv2.rectangle(frame, (int(bboxes_xyxy[pos][0]), int(bboxes_xyxy[pos][1])), (int(bboxes_xyxy[pos][2]), int(bboxes_xyxy[pos][3])), (255,255,255), 2)\n",
    "                    cv2.putText(frame, f\"Motor-{obj_id_to_track}\", (int(bboxes_xyxy[pos][0]) + 10, int(bboxes_xyxy[pos][1]) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)        \n",
    "\n",
    "                #frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                #frame_bgr = cv2.resize(frame_bgr, (width, height))\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "            else:\n",
    "                #frame = cv2.resize(frame, (width, height))\n",
    "                #frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "        #display_image(frame_bgr)\n",
    "        #output_video.write(frame_bgr)\n",
    "        output_video.write(frame)\n",
    "\n",
    "# Liberar recursos\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv8 Track all objects in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)\n",
    "objects = ['car']\n",
    "number_class_list = []\n",
    "\n",
    "if objects!=None:\n",
    "    if objects!=['all']:\n",
    "        for object in objects: \n",
    "            number_class_list.append(classes.index(object))\n",
    "    elif objects == ['all']:\n",
    "        number_class_list = list(range(len(classes)))\n",
    "\n",
    "# Images folder path\n",
    "#img_folder = os.path.join(sequences_folder, 'uav0000317_00000_s') #motor\n",
    "#img_folder = os.path.join(sequences_folder, 'uav0000053_00264_s') #people\n",
    "img_folder = os.path.join(sequences_folder, 'uav0000115_00606_s') #car\n",
    "\n",
    "img_names = sorted(os.listdir(img_folder))\n",
    "\n",
    "# Video size\n",
    "width, height = 1280, 720\n",
    "\n",
    "# Codec and VideoWriter\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = 30\n",
    "output_video = cv2.VideoWriter(r'.\\outputs\\Task3\\output_yolo.mp4', codec, fps, (width, height))\n",
    "\n",
    "# Frame processing\n",
    "for i, img in enumerate(img_names):\n",
    "    img_fullpath = os.path.join(img_folder, img)\n",
    "    frame = cv2.imread(img_fullpath)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if frame is not None:\n",
    "        # Redimensionar la imagen si es necesario\n",
    "        if width and height:\n",
    "            results = model.track(frame, persist=True, verbose=False, conf=0.3, iou=0.5, classes=number_class_list, imgsz=704, tracker=r'.\\botsort_custom.yaml')\n",
    "            annotated_frame = results[0].plot()               \n",
    "            annotated_frame = cv2.resize(annotated_frame, (width, height))\n",
    "            #output_video.write(cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))\n",
    "            output_video.write(annotated_frame)\n",
    "\n",
    "# Liberar recursos\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)\n",
    "objects = ['car']\n",
    "number_class_list = []\n",
    "\n",
    "if objects!=None:\n",
    "    if objects!=['all']:\n",
    "        for object in objects: \n",
    "            number_class_list.append(classes.index(object))\n",
    "    elif objects == ['all']:\n",
    "        number_class_list = list(range(len(classes)))\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"path/to/video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Video size\n",
    "width, height = 1280, 720\n",
    "\n",
    "# Codec and VideoWriter\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = 30\n",
    "output_video = cv2.VideoWriter(r'.\\outputs\\Task3\\output.mp4', codec, fps, (width, height))\n",
    "\n",
    "# Frame processing\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        # Redimensionar la imagen si es necesario\n",
    "        if width and height:\n",
    "            results = model.track(frame, persist=True, verbose=False, conf=0.3, iou=0.5, classes=number_class_list, imgsz=704)\n",
    "            annotated_frame = results[0].plot()               \n",
    "            annotated_frame = cv2.resize(annotated_frame, (width, height))\n",
    "            #output_video.write(cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))\n",
    "            output_video.write(annotated_frame) \n",
    "    # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('proyectos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9046291224b9ae991683ef7a0ef8fd462791dccad48d624cd221e38879383f70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
